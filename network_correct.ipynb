{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90126d5-9236-47a4-b1c0-daf3fd71eb61",
   "metadata": {},
   "source": [
    "# ToDo: \n",
    "- criticality of intersections. should all of them be nodes?\n",
    "- try building network without OSM data [done]\n",
    "- add coordinates to nodes to plot the network? [done]\n",
    "- try building network with OSM data (first,requires I add width to OSM data)\n",
    "- create network of all roads, with weights [done]\n",
    "- investigate algorithm for filling up links randomly with weight threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda74bf-63b3-414a-9d6f-707e0d4590b0",
   "metadata": {},
   "source": [
    "# Road Graph network of Milan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921a264-6035-4060-8406-8876f7ad2240",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256734d7-bd17-48d7-b632-829d6f0bc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7c10b-b272-434f-ad68-6e1742c36f2f",
   "metadata": {},
   "source": [
    "### Import and initial cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2d99c5-4014-472b-a8cf-ea1ad0e8f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_path = \"C:/Users/rickb/Documents/scuola/THESIS/datasets/Milan/DBT_2020/SHAPE/AC_VEI_AC_VEI_SUP_SR.shp\"\n",
    "gdf = gpd.read_file(vehicle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4071dc3-1d9a-4ea9-9e85-a53d5edb3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.drop(['AC_VEI_FON', 'AC_VEI_LIV', 'AC_VEI_SED', 'CLASSREF'],axis = 1, inplace = True)\n",
    "gdf.rename(columns={'SUBREGID':'ID', 'NOME': 'NAME', 'AC_VEI_ZON': 'TYPE'}, inplace = True)\n",
    "\n",
    "pattern1 = ('01','02')\n",
    " # portions of road (e.g not intersections or parking lots) start with 01 in TYPE\n",
    " # intersections, squares, and roundabouts start with 02 in TYPE\n",
    "gdf = gdf[~gdf['NAME'].str.contains('TANGENZIALE', regex = False)] #removing tangenziali\n",
    "gdf = gdf[gdf.TYPE.str.startswith(pattern1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aacafd-7bab-4f63-88bb-07ca841f00c1",
   "metadata": {},
   "source": [
    "We use the same crs as OSM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50939c54-0a0d-45b1-a321-cfcc76bf278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OSM_crs = 3857\n",
    "gdf.to_crs(epsg=OSM_crs, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa809515-3082-4689-92eb-fecca26da661",
   "metadata": {},
   "source": [
    "### Some useful functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c6951-9eca-405c-9b2f-fa67a5c9f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divides gdf into intersections and roads\n",
    "\n",
    "def ints_and_roads(gdf):\n",
    "\n",
    "    pattern2 = ('01')\n",
    "    pattern3 = ('02') \n",
    "    pattern4 = ('0102')\n",
    "    roads = gdf[(gdf.TYPE.str.startswith(pattern2)) & ~ (gdf.TYPE.str.startswith(pattern4))]\n",
    "    ints = gdf[(gdf.TYPE.str.startswith(pattern3)) | (gdf.TYPE.str.startswith(pattern4))]\n",
    "    return ints, roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7302e4b-0924-413c-a482-1a2bf0007d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function creates geodataframe with all streets of gdf within distance dist (in meters) of street.\n",
    "#street is a geodataframe, dist is a positive number, and gdf is the geodataframe dataset.\n",
    "\n",
    "def within_dist(street, dist, gdf):\n",
    "\n",
    "    temp = street.copy()\n",
    "    temp.geometry = temp.geometry.buffer(dist)\n",
    "    temp = temp.filter(['geometry']) #so sjoin doesn't give suffixes and i don't have to rename later\n",
    "    gdf_distanced = gdf.sjoin(temp, how='inner', predicate='intersects')\n",
    "    gdf_distanced = gdf_distanced.dropna()\n",
    "    gdf_distanced = gdf_distanced[~gdf_distanced.index.duplicated(keep='first')] #removes streets that are in more than one polygon's buffer\n",
    "    gdf_distanced = gdf_distanced.iloc[:,:-1] #drops index_R column\n",
    "    return gdf_distanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f9b7a-cf68-46f5-9ac8-a3ca6a33726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define a variation of the within_dist function. This one keeps duplicate entries because they are useful for creating the graph later on.\n",
    "\n",
    "def within_dist_dupes(street, dist, gdf):\n",
    "\n",
    "    temp = street.copy()\n",
    "    temp.geometry = temp.geometry.buffer(dist)\n",
    "    temp = temp.filter(['geometry']) #so sjoin doesn't give suffixes and i don't have to rename later\n",
    "    gdf_distanced = gdf.sjoin(temp, how='inner', predicate='intersects')\n",
    "    gdf_distanced = gdf_distanced.dropna()\n",
    "    return gdf_distanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad3f69-7251-4441-a168-e4b1b927957c",
   "metadata": {},
   "source": [
    "### Average width calculation: \n",
    "Area is length times width for rectangles.  \n",
    "Perimeter is 2(length) + 2(width)  \n",
    "$A = lw$  \n",
    "$P = 2l+2w$  \n",
    "brings us to solve for width as   \n",
    "\n",
    "$P = 2\\frac{A}{w}+2w$ \n",
    "so  \n",
    "$w^2 -\\frac{P}{2}w+A = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6540f50-f2ed-4711-9efb-0200b04dd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates width of all entries in gdf, and adds them to a width column. Assumes rectangular equivalent shape for polygons\n",
    "\n",
    "def calc_widths(gdf):\n",
    "    gdf['temp'] = 1 # create column of ones\n",
    "    gdf['SemiPeri'] = -gdf.length/2 # i need it negative for the equation\n",
    "    gdf['Area'] = gdf.area\n",
    "    def calculate_roots(row):\n",
    "        coefficients = row[['temp', 'SemiPeri', 'Area']].values\n",
    "        roots = np.roots(coefficients).real\n",
    "        return roots\n",
    "\n",
    "    #gdf['roots'] = gdf.apply(calculate_roots, axis=1)\n",
    "    gdf['roots'] = gdf[['temp', 'SemiPeri', 'Area']].apply(calculate_roots, axis=1)\n",
    "    gdf[['root1', 'root2']] = pd.DataFrame(gdf['roots'].tolist(), index=gdf.index)\n",
    "    gdf['width'] = gdf['root2']\n",
    "    gdf = gdf.drop([ 'Area', 'temp', 'SemiPeri', 'roots', 'root2'], axis = 1)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5150d05-cb47-4cca-9759-8f445e8e9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = calc_widths(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff862579-e604-41b1-b344-2d136683606b",
   "metadata": {},
   "source": [
    "NB with this method root2 is always the width because all segments of road are longer than they are wide, and root2 is always the smaller of the two roots, by construction of the method. at most there can be entries where root1=root2, which would mean that they both equal the width."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddbe926-6967-47f0-a94f-03c96dbca617",
   "metadata": {},
   "source": [
    "## Useful subdivisions\n",
    "We can add info into our dataset about neighborhoods, municipal zones, and even just custom subdivisions of streets within a certain\n",
    "radius of another.  \n",
    "These are all useful for visualization of the dataset, and for testing algorithms on subsets smaller than the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa7c2f-3bc0-4f59-8eeb-189ca80a0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopandas.tools import sjoin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa416ae-8780-4e02-8a3e-ced95fa4c9e3",
   "metadata": {},
   "source": [
    "### Municipal info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92170fba-ac38-4fca-85c7-e6284df56801",
   "metadata": {},
   "outputs": [],
   "source": [
    "municipal_path = \"C:/Users/rickb/Documents/scuola/THESIS/datasets/Milan/DBT_2020_new/SHAPE/Municipi.shp\"\n",
    "gdf_M = gpd.read_file(municipal_path)\n",
    "gdf_M = gdf_M.to_crs(epsg = OSM_crs)\n",
    "\n",
    "gdf = gdf.sjoin(gdf_M, how = 'inner',predicate = 'intersects') # requires gpd > 0.9\n",
    "#gdf_zone = gpd.sjoin(gdf_roads_piaz, gdf2, how = 'inner', op = 'intersects') #is equivalent, with older syntax\n",
    "gdf = gdf.drop(['AREA', 'PERIMETRO', 'index_right'], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5005810-c493-4731-8b48-845e7a498018",
   "metadata": {},
   "source": [
    "### Neighborhood info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01581c94-b6db-40de-bcd7-70b94ea35dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_path = \"C:/Users/rickb/Documents/scuola/THESIS/datasets/Milan/Quartieri milano_real/NIL_WM.shp\"\n",
    "gdf_N = gpd.read_file(neighborhood_path)\n",
    "gdf_N = gdf_N.to_crs(epsg = OSM_crs)\n",
    "gdf_N = gdf_N.drop(['Valido_dal', 'Fonte', 'Shape_Leng', 'Shape_Area', 'OBJECTID', 'Valido_al'] ,axis=1)\n",
    "\n",
    "\n",
    "gdf = gdf.sjoin(gdf_N, how = 'inner',predicate = 'intersects')\n",
    "gdf = gdf.drop(['index_right'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395701e3-9df9-44c0-b333-ab3e9502b40c",
   "metadata": {},
   "source": [
    "Finally, let's split our main dataframe into two: one with only roads, and one with only intersections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a3c8b-deb5-4baf-9431-87ac607ebea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ints, roads = ints_and_roads(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb7fd1-4a92-48c7-a224-e6f9d0995bb9",
   "metadata": {},
   "source": [
    "### Example: The Stadera Neighborhood of Milan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5de3ba-2bd0-48f5-8216-1db3976f9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now isolate an example neighborhood\n",
    "tot_Stadera = gdf[gdf['NIL'] == 'STADERA - CHIESA ROSSA - Q.RE TORRETTA - CONCA FALLATA']\n",
    "ints_Stadera, roads_Stadera = ints_and_roads(tot_Stadera)\n",
    "#and a single street in that neighborhood\n",
    "tot_Volv = tot_Stadera[tot_Stadera['NAME'] == 'VIA VOLVINIO']\n",
    "ints_Volv, roads_Volv = ints_and_roads(tot_Volv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f56b95-59ea-4f41-8a3b-d468ec1044e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize = (8,8))\n",
    "\n",
    "ax[0].set_title(f\"The Stadera Neighborhood of Milan\")\n",
    "tot_Stadera.plot(ax = ax[0], alpha = 0.5, column = 'TYPE')\n",
    "#plt.legend(title='Type', labels=tot_Stadera['TYPE'].unique())\n",
    "cx.add_basemap(ax[0], crs=gdf_N.crs, zoom = 15, source=cx.providers.CartoDB.Positron) #providers.Esri.WorldImagery for satellite\n",
    "ax[1].set_title(\"and a single street from it\")\n",
    "tot_Volv.plot(ax = ax[1], alpha = 0.5, column = 'NAME')\n",
    "cx.add_basemap(ax[1], crs=gdf_N.crs, zoom = 15, source=cx.providers.CartoDB.Positron) #providers.Esri.WorldImagery for satellite\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9290bc75-a9fe-47d6-b539-cbb0a519f371",
   "metadata": {},
   "source": [
    "### Example 2: Creating custom ranges by distance\n",
    "\n",
    "We use within_dist to create a Geodataframe with all roads within a given distance from the road given as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeabfe6-97e3-4591-ac49-201ddc837c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with an example road (you can even use more than one road)\n",
    "tot_Volv = gdf[gdf['NAME'] == 'VIA VOLVINIO']\n",
    "ints_Volv, roads_Volv = ints_and_roads(tot_Volv)\n",
    "\n",
    "M = 100 #distance in meters\n",
    "temp = within_dist(tot_Volv, M, gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350bf4ee-144f-4d92-a400-2c7882906494",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (8,8))\n",
    "\n",
    "temp.plot(ax = ax[0], alpha = 0.5, column = 'TYPE')\n",
    "plt.legend(title='Type', labels=temp['TYPE'].unique())\n",
    "cx.add_basemap(ax[0], crs=gdf.crs, zoom = 15, source=cx.providers.CartoDB.Positron) #providers.Esri.WorldImagery for satellite\n",
    "plt.title(f\"roads within {M} meters from Via Volvinio\")\n",
    "temp.plot(ax = ax[1], alpha = 0.5, column = 'NAME')\n",
    "cx.add_basemap(ax[1], crs=gdf.crs, zoom = 15, source=cx.providers.CartoDB.Positron) #providers.Esri.WorldImagery for satellite\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997596c-c40f-4bc7-bdb3-5640553b5386",
   "metadata": {},
   "source": [
    "## Final preprocessing steps: fixing adjacent roads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d2955-7575-4098-a5dc-bd8f9c2e972a",
   "metadata": {},
   "source": [
    "Here is one of the criticalities: for some reason, some intersections are connected by chains of \"runway\" polygons with no intersections between them.  \n",
    "For example, here we see two nodes of the network that should be connected, that don't count as connected in the graph because they are separated by more than one polygon. you can tell from the plot on the right that the polygons are in fact separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618cbc7-5c66-4bbd-95f7-4a9e7f2b4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meda = gdf[gdf.NAME == 'VIA GIUSEPPE MEDA']\n",
    "meda_int = ints[ints.NAME == 'VIA GIUSEPPE MEDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426da54-ee39-4a48-9cc2-ca592bf2b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (4,4))\n",
    "k = within_dist(meda.loc[2277:2280], 10, gdf)\n",
    "k.plot(column = 'TYPE', ax = ax[0])\n",
    "k.plot(column = 'ID', ax = ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b2db0e-46a1-4052-a8a6-aaebca1c4729",
   "metadata": {},
   "source": [
    "### Solution implementation:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e2885-e12d-475d-8fd7-bf76d4a6f5f3",
   "metadata": {},
   "source": [
    "#### 1) Unary union "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6eb369-3d11-4432-8941-c111bdab639a",
   "metadata": {},
   "source": [
    "The easiest, most automatic method to get adjacent geometries into one is using unary union. It automatically gives me what i need. The problem is that i lose all info which is not geometry. I can get everything from TYPE to NIL back easily but, i'd lose NAME and ID. \n",
    "I create a new dataset with all the roads (obtained through iteration...) and then add the dataset with the intersections to it.\n",
    "\n",
    "Dissolve method is conceptually more complicated, but more efficient and elegant. See below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ffb25-f8f0-465f-a67e-23de4f218266",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = gdf.copy()\n",
    "q.to_crs(epsg = OSM_crs, inplace = True)\n",
    "pattern1 = ('01','02')\n",
    "q = q[~q['NAME'].str.contains('TANGENZIALE', regex = False)] #removing tangenziali\n",
    "q = q[q['TYPE'].str.startswith(pattern1)]\n",
    "q.reset_index(inplace = True, drop = True)\n",
    "intq, nonq = ints_and_roads(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e37a1-fb99-4993-b849-64783a9a747b",
   "metadata": {},
   "source": [
    "one for intersections and one for non intersections. we need to recreate our q dataset with all our roads made adjacent. it takes some steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f66f05-bf73-4763-9d1c-d8b9abc24d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qq = gpd.geoseries.GeoSeries([geom for geom in nonq.unary_union.geoms])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70100322-9c9b-4812-9621-179e650cdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "qqq = gpd.geoseries.GeoSeries([geom for geom in intq.unary_union.geoms])\n",
    "#do i really need to do this too? hmmm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dabf74-66d7-4e9a-8180-10df40f2829e",
   "metadata": {},
   "source": [
    "NB in doing this we're losing info on the names of the streets. I'm not a huge fan of this fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12ac5b-0a07-4f35-bdad-aff54f38eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(qqq), len(intq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467dfe9-f6cb-4f77-aa25-62bc1e5c6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(nonq), len(qq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47a3b0-b0bc-4518-a5c2-dffdbb99586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_intq = gpd.GeoDataFrame(geometry = qqq, crs = OSM_crs)\n",
    "new_intq['TYPE'] = '02'\n",
    "new_intq.set_geometry('geometry');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9667906-db6b-44b8-bd73-0bfa9a9687a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nonq = gpd.GeoDataFrame(geometry = qq, crs = OSM_crs)\n",
    "new_nonq['TYPE'] = '01'\n",
    "new_nonq.set_geometry('geometry');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ec454-db92-4b74-b9c0-20961952d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "intq = calc_widths(new_intq)\n",
    "\n",
    "nonq = calc_widths(new_nonq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f141f1-0518-4241-9e17-1d648d20f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_path = \"C:/Users/rickb/Documents/scuola/THESIS/datasets/Milan/Quartieri milano_real/NIL_WM.shp\"\n",
    "\n",
    "nonq = nonq.to_crs(epsg = OSM_crs)\n",
    "nonq = nonq.sjoin(gdf_N, how = 'inner', predicate = 'intersects')\n",
    "nonq = nonq.drop(['index_right'], axis = 1)\n",
    "intq = intq.sjoin(gdf_N, how = 'inner', predicate = 'intersects')\n",
    "intq = intq.drop(['index_right'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032577fa-d9d0-4fe3-8d85-19693ca2c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonq_S = nonq[nonq.NIL == 'STADERA - CHIESA ROSSA - Q.RE TORRETTA - CONCA FALLATA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c1dea-c5a1-4fc4-94fa-e4a3ed4e1f21",
   "metadata": {},
   "source": [
    "recreating single dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448d8ab-c58b-49b4-a24b-213cfbe50ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = pd.concat([intq,nonq])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e63aa0-a311-49da-ae02-065f5afd5523",
   "metadata": {},
   "source": [
    "#### 2) Dissolve\n",
    "\n",
    "Starting from entire dataset, divide into intersections, and non intersections (roads).  \n",
    "From there, roads with adjacent roads will be the complementary set of within_dist(int, 1, non_int).\n",
    "This is because within_dist(...) gives all non_ints (roads) that are beside intersections.  \n",
    "Now we have roads not adjacent to any intersection; we're missing the roads that these roads are adjacent to.  \n",
    "we use within_dist_dupes(roads, 1, non_int) to get all our chains of roads, grouped together by an 'index_right' column.  \n",
    "we use dissolve(by = 'index_right') to make each chain of roads into a single one.  \n",
    "We take the complement of the result of within_dist_dupes(...), and concat it with our dissolved gdf.  \n",
    "This is now the entire road dataset. Concat this with the intersections, and we have now treated our dataset properly and can proceed with making our graph.  \n",
    "\n",
    "NB I tested this on a few roads manually (namely VIA GIUSEPPE MEDA, VIA ASCANIO SFORZA etc.) and everything seemed fine. I imagine there may be some problems with longer chains of roads, but generally I'm quite confident that the amount of critical cases is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2f310-d4af-47d6-ad87-3fd9f6b3682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = gdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5941e-6174-48d7-8d47-8d6b3599dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes gdf, dissolves adjacent roads into single roads, and replaces them into the original gdf\n",
    "\n",
    "def road_dissolver(gdf):\n",
    "    ints, roads = ints_and_roads(gdf)\n",
    "    there = within_dist(ints, 1, roads) #all roads that have adjacent intersections\n",
    "    not_there = roads[~roads.index.isin(there.index)] #all roads that don't\n",
    "    adj = within_dist_dupes(not_there, 1, roads)\n",
    "    not_dissolved = roads[~roads.index.isin(adj.index)] # i build complement before dissolving because dissolving doesn't preserve all indices\n",
    "    dissolved = adj.dissolve(by = 'index_right')\n",
    "    #now concat back to retrieve entire dataset\n",
    "    new_roads = pd.concat([dissolved, not_dissolved])\n",
    "    new_gdf = pd.concat([new_roads, ints])\n",
    "    new_gdf.reset_index(inplace = True, drop = True)\n",
    "    return new_gdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3961413-a641-4e6b-82fc-08296e43f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = road_dissolver(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afa06d8-aefb-41d7-a50b-28881019beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = calc_widths(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14b19f-314e-43ec-b6c1-11895217b9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44f06fd5-4001-4085-b11f-5089ad82b0d8",
   "metadata": {},
   "source": [
    "# The Network\n",
    "Make intersections the nodes, and make roads the edges. road width are the weights.  \n",
    "NB for now we will consider all streets in the manner which is most convenient, i.e as two-way streets, unless otherwise specified.\n",
    "Due to how the dataset is built, sometimes there are two consecutive roads without intersections. We must slightly simplify the dataset so that this isn't an issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be15d4-5f3c-422d-b661-0f5ef8a9b226",
   "metadata": {},
   "source": [
    "remember:\n",
    "- intersections as nodes.\n",
    "- the actual roads as edges.\n",
    "- their width and name will be weights/edge attributes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623b5bc-f708-497b-a17d-05806a7edffe",
   "metadata": {},
   "source": [
    "To find the edges of the network, we take an intersection and use the within_dist function with a distance = 1 to find\n",
    "all roads that are immediately adjacent to the intersection. \n",
    "These are the \"stubs\" of our graph, i.e lines that connect to a node and nothing else.  \n",
    "When we do this for all intersections, the edges of the network will simply be the common stubs between pairs of nodes.  \n",
    "Our road network will be a MultiGraph, because some intersections may be connected by two or more different roads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8fa192-5350-4be2-bc64-dcf58927ca07",
   "metadata": {},
   "source": [
    "This function is only called on dataframes with indexes from 0 to N.  \n",
    "When we sjoin an intersection with its surrounding streets, our resulting dataframe will tell us, in each row, the index of the intersection\n",
    "that the given road is adjacent to. this information will be contained in \"index_right\", which is the new name given to what was the intersection index in the original dataframe.  \n",
    "\n",
    "This means each row of our sjoined dataframe represents a stub of the node \"index_right\".  \n",
    "\n",
    "\n",
    "We divide into N dataframes based on index_right, to have a dataframe of the adjacent edges to one road (i.e the stubs).   \n",
    "there is a connection between dataframe_i and dataframe_j for each common stub between the two.  \n",
    "\n",
    "Finally, the function that performs these operations and finds the connections is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835fb88-a947-4051-8522-64c609eaaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edges(gdf_tot):\n",
    "\n",
    "    #prep\n",
    "    #takes dataset with roads and intersections, creates edgelist of nodes with weights of edges\n",
    "    pattern1, pattern2, pattern3 = '01', '02', '0102'\n",
    "    no_ints = gdf_tot[(gdf_tot.TYPE.str.startswith(pattern1)) & ~ (gdf_tot.TYPE.str.startswith(pattern3))]\n",
    "    ints = gdf_tot[(gdf_tot.TYPE.str.startswith(pattern2)) | (gdf_tot.TYPE.str.startswith(pattern3))]\n",
    "    #we need indices from 0 --> reset\n",
    "    ints.reset_index(inplace = True, drop = True)\n",
    "    no_ints.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "    #body\n",
    "    stubs = within_dist_dupes(ints, 1, no_ints) #all stubs, i.e all roads connected to all nodes\n",
    "    grouped = stubs.groupby('index_right') #one dataframe for each node\n",
    "    edges = {} # will contain intersections of each node \n",
    "    edge_list = pd.DataFrame(columns = ['from','to','weight'])\n",
    "    for node, group in grouped:\n",
    "        stubs = stubs[stubs['index_right'] != node] #removing \"self\" from gdf that we will merge onto, to avoid self connections. also removes redundancies  \n",
    "        edges[node] = pd.merge(group,stubs, on = 'ID', how = 'inner')\n",
    "        edge_list_temp = pd.DataFrame({'from': edges[node].index_right_x, 'to': edges[node].index_right_y, 'weight': edges[node].width_x})\n",
    "        edge_list = pd.concat([edge_list if not edge_list.empty \n",
    "                               else None,edge_list_temp])\n",
    "    \n",
    "    \n",
    "    #exceptions    \n",
    "    #adds self-edges to nodes that don't appear in to or from\n",
    "    conc = pd.concat([edge_list['from'], edge_list['to']])\n",
    "    all = set(range(0, len(ints))) #all possible nodes\n",
    "    there = set(conc.unique()) #the nodes we actually have\n",
    "    not_there = sorted(list(all-there)) #missing nodes (irregardless of why they're missing for the moment)\n",
    "    df_self = pd.DataFrame({'from': not_there, 'to': not_there, 'weight': [1] * len(not_there)})\n",
    "    df_self\n",
    "    edge_list = pd.concat([edge_list, df_self])\n",
    "    return edge_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00639a-a015-46c6-a9a2-eff703113b8a",
   "metadata": {},
   "source": [
    "## Demostration of a problem:\n",
    "When working with an UNPROCESSED gdf:\n",
    "After extensive testing, it seems clear that making the network works quite well on a small scale, but:\n",
    "at a certain point you will encounter a series of consecutive roads without an intersection.  \n",
    "Unfortunately, without handling these exceptions, the total network ends up being divided into many giant components.  \n",
    "This doesn't make sense, since a road network should be connected.  \n",
    "That is why we preprocess our gdf with unary union or with dissolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12ea18-a139-4ae6-9fc2-6875efbf45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1400\n",
    "temp = within_dist(tot_Volv, M, gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bf3c4-8ef9-449a-a918-6cbaea02c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = make_edges(temp)\n",
    "G = nx.from_pandas_edgelist(edges, 'from', 'to', edge_attr=[\"weight\"] , create_using=nx.MultiGraph())\n",
    "\n",
    "Gcc = sorted(nx.connected_components(G), key = len, reverse = True)\n",
    "print(len(Gcc[0]), len(Gcc[1]),len(Gcc[2]))\n",
    "\n",
    "intt, nont = ints_and_roads(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc984fc8-559b-4548-a506-1949789b2678",
   "metadata": {},
   "source": [
    "This already shows that the second and third largest components are much larger than they should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed8529-df3f-498e-bb71-9855ca2a6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "cent = intt.centroid\n",
    "coordinates = np.column_stack((cent.geometry.x, cent.geometry.y))\n",
    "positions = dict(zip(sorted(G.nodes), coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b05a90-bc7d-4947-a40f-09f45c4a6b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "#temp.plot(marker=\".\", column= \"TYPE\", ax=ax, alpha = 0.5) to add underlying polygons\n",
    "\n",
    "ax.set_title(\"Partial road graph, with clusters highlighted\")\n",
    "ax.axis(\"off\")\n",
    "colorlist = [ 'r', 'g', 'b', 'y', 'orange']\n",
    "#create subgraphs, get nodelist and edgelist. pass to the two functions. possible cmap of edges by width\n",
    "for i in range(0, len(Gcc)):\n",
    "    nx.draw_networkx_nodes(G, positions, nodelist = list(Gcc[i]), \n",
    "                           node_color = colorlist[i%5], ax=ax, \n",
    "                           node_size=10)\n",
    "edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "nx.draw_networkx_edges(G, positions, edge_color = weights, \n",
    "                       edge_cmap = plt.cm.inferno, \n",
    "                       edge_vmin = min(weights), edge_vmax = max(weights),\n",
    "                       ax = ax)    \n",
    "#labels = nx.draw_networkx_labels(G, pos=positions, font_size = 6)\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.DarkMatterNoLabels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc3e3f-1c29-43bd-a997-40bf41b9b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.colormaps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf816fc3-8f81-426b-9775-bc241db6ef07",
   "metadata": {},
   "source": [
    "We can see that there are large componenents of the network that never connect, even though there are two nodes that look like there should be a connection between them.  \n",
    "That is why we preprocess with unary_union or Dissolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86ce55d-5514-4d33-ae7f-c35e448c1233",
   "metadata": {},
   "source": [
    "### Unary union Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb25a50b-9a5e-465e-b8d5-e249ce3b4eb3",
   "metadata": {},
   "source": [
    "The following section requires the \"Unary Union\" section to have been executed in order to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c2033-d7d5-4118-8dd2-7d38fbfb0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q['ID'] = q.index #need to have ID column for \"make_edges\" to work\n",
    "edge_list = make_edges(q)\n",
    "G = nx.from_pandas_edgelist(edge_list, 'from', 'to', edge_attr=[\"weight\"] , create_using=nx.MultiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c18950-0ac4-45f5-9589-82cbe1695927",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gcc = sorted(nx.connected_components(G), key = len, reverse = True)\n",
    "#print(len(Gcc[0]), len(Gcc[1]),len(Gcc[2]))\n",
    "intq, nonq = ints_and_roads(q)\n",
    "print(len(Gcc[0]), len(intq)) #to see how large the giant component is comparted to total nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d16fb6-a60b-4866-b0ea-4ccb2b89c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add positional information to nodes:\n",
    "\n",
    "cent = intq.centroid\n",
    "coordinates = np.column_stack((cent.geometry.x, cent.geometry.y))\n",
    "positions = dict(zip(sorted(G.nodes), coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6302c5-c013-472a-88f1-ee01595a5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "#temp.plot(marker=\".\", column= \"TYPE\", ax=ax, alpha = 0.5)\n",
    "\n",
    "ax.set_title(\"Partial road graph, with clusters highlighted\")\n",
    "ax.axis(\"off\")\n",
    "colorlist = [ 'r', 'g', 'b', 'y', 'orange']\n",
    "#create subgraphs, get nodelist and edgelist. pass to the two functions. possible cmap of edges by width\n",
    "for i in range(0, len(Gcc)):\n",
    "    nx.draw_networkx_nodes(G, positions, nodelist = list(Gcc[i]), \n",
    "                           node_color = colorlist[i%5], ax=ax, \n",
    "                           node_size=1.5)\n",
    "edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "nx.draw_networkx_edges(G, positions, edge_color = weights, \n",
    "                       edge_cmap = plt.cm.inferno, \n",
    "                       edge_vmin = min(weights), edge_vmax = max(weights),\n",
    "                       ax = ax)    \n",
    "#labels = nx.draw_networkx_labels(G, pos=positions, font_size = 6)\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec465e-0f9d-4799-8b33-753117dcfd93",
   "metadata": {},
   "source": [
    "### Dissolve Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc5bfa2-9880-47d6-8d7a-639165135cf1",
   "metadata": {},
   "source": [
    "The following section requires the \"Dissolve\" section to have been executed in order to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267aa72-77b6-470c-bd3e-a62e2d679ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = make_edges(all)\n",
    "G = nx.from_pandas_edgelist(edge_list, 'from', 'to', edge_attr=[\"weight\"] , create_using=nx.MultiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec43e0-8ca2-4b23-a6be-00a417f62f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gcc = sorted(nx.connected_components(G), key = len, reverse = True)\n",
    "#print(len(Gcc[0]), len(Gcc[1]),len(Gcc[2]))\n",
    "ints, roads = ints_and_roads(all)\n",
    "print(len(Gcc[0]), len(ints)) #to see how large the giant component is comparted to total nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecbb79-f8a3-4a66-8cab-5c2079d27dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cent = ints.centroid\n",
    "coordinates = np.column_stack((cent.geometry.x, cent.geometry.y))\n",
    "positions = dict(zip(sorted(G.nodes), coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af4151-09cc-478b-8829-6719b5d22695",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "#temp.plot(marker=\".\", column= \"TYPE\", ax=ax, alpha = 0.5)\n",
    "\n",
    "ax.set_title(\"Partial road graph, with clusters highlighted\")\n",
    "ax.axis(\"off\")\n",
    "colorlist = [ 'r', 'g', 'b', 'y', 'orange']\n",
    "#create subgraphs, get nodelist and edgelist. pass to the two functions. possible cmap of edges by width\n",
    "for i in range(0, len(Gcc)):\n",
    "    nx.draw_networkx_nodes(G, positions, nodelist = list(Gcc[i]), \n",
    "                           node_color = colorlist[i%5], ax=ax, \n",
    "                           node_size=1, alpha = 0.3)\n",
    "edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "nx.draw_networkx_edges(G, positions, edge_color = weights, \n",
    "                       edge_cmap = plt.cm.inferno, \n",
    "                       edge_vmin = min(weights), edge_vmax = max(weights),\n",
    "                       ax = ax)   \n",
    "#labels = nx.draw_networkx_labels(G, pos=positions, font_size = 6)\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5171e-ca70-4264-b273-80bd76199e8c",
   "metadata": {},
   "source": [
    "Way more self edges (approx 500), although most of them near the boundaries of the graph. need to understand why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6f987-4955-4bb7-9f0f-74de937988f8",
   "metadata": {},
   "source": [
    "## Percolation trials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6605904-2627-452c-afa2-5281ffd33ed1",
   "metadata": {},
   "source": [
    "My goal for now is to find the percolation threshold based on width. In other words, does my network have a giant component? how many wide roads can i remove before i don't have one anymore? and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2b6db-b22b-4164-95e9-2745f0ba2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gc = sorted(nx.connected_components(G), key = len, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015b18f-31bd-4ae6-a989-8c72af3c5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = len(Gc[0])/len(G) #percentage of network occupied by largest connected component.\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dc695b-d22c-480f-ac9e-a32a40ec6f1d",
   "metadata": {},
   "source": [
    "NB S is good for preliminary analysis because it treats all nodes and edges equally. we may want to add some classification of importance of which nodes we remove later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b1ba7-818c-4076-953a-f9711681d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesss=sorted(G.edges(data=True), key=lambda edge: edge[2].get('weight', 1)) #sorts edges by width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f3ce30-f5cd-43b9-9b3d-5cf11ab5df7d",
   "metadata": {},
   "source": [
    "create range of min to max width and do various removals, then plot S vs width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b672a-5d4b-40c9-b6c1-8c3ea41d9582",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.linspace(edge_list.weight.min(), edge_list.weight.max()/2, 30)\n",
    "S_list = {}\n",
    "S2_list= {} #second largest component list\n",
    "for i in r:\n",
    "    edge_list_t = edge_list[edge_list.weight > i]\n",
    "    Gt = nx.from_pandas_edgelist(edge_list_t, 'from', 'to', edge_attr=[\"weight\"] , create_using=nx.MultiGraph())\n",
    "    Gcc = sorted(nx.connected_components(Gt), key=len, reverse=True)\n",
    "    S_list[i] = len(Gcc[0])/len(G)\n",
    "    if len(Gcc) > 1:\n",
    "        S2_list[i] = len(Gcc[1])/len(G)\n",
    "    else: S2_list[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c08c2-d8f4-449a-acd1-4e93cc09a82e",
   "metadata": {},
   "source": [
    "breakdown clearly happens between 12 and 13m street removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a7d83-3ee9-4b44-8072-8454f1fcaf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = subplots(1,1, figsize(8,8))\n",
    "keys = [float(key) for key in S_list.keys()]\n",
    "\n",
    "# Extract values\n",
    "S_values = list(S_list.values())\n",
    "S2_values = list(S2_list.values())\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize = (6,6))\n",
    "ax2 = ax.twinx()\n",
    "# Plot keys vs values\n",
    "ax.plot(keys, S_values, marker='o')\n",
    "ax2.plot(keys, S2_values, color = 'red')\n",
    "ax.set_xlabel('min width of streets kept (m)')\n",
    "ax.set_ylabel('fractional size of giant component')\n",
    "ax2.set_ylabel('second largest component')\n",
    "plt.title('Percolation test')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e741d79-9261-4ad7-8d51-a47a5796ccde",
   "metadata": {},
   "source": [
    "### now removing highest to lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21e7f9-36b9-46e4-b3de-1620902c7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.linspace(edge_list.weight.max()/2, edge_list.weight.min()+0.1,  20)\n",
    "S_list_rev = {}\n",
    "S2_list_rev = {}\n",
    "for i in r:\n",
    "    edge_list_t = edge_list[edge_list.weight < i]\n",
    "    Gt = nx.from_pandas_edgelist(edge_list_t, 'from', 'to', edge_attr=[\"weight\"] , create_using=nx.MultiGraph())\n",
    "    Gcc = sorted(nx.connected_components(Gt), key=len, reverse=True)\n",
    "    S_list_rev[i] = len(Gcc[0])/len(G)\n",
    "    S2_list_rev[i] = len(Gcc[1])/len(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f0efa-9493-41aa-812f-59cb1bd88387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = subplots(1,1, figsize(8,8))\n",
    "keys = [float(key) for key in S_list_rev.keys()]\n",
    "\n",
    "# Extract values\n",
    "S_rev_values = list(S_list_rev.values())\n",
    "S2_rev_values = list(S2_list_rev.values())\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize = (6,6))\n",
    "ax2 = ax.twinx()\n",
    "# Plot keys vs values\n",
    "ax.plot(keys, S_rev_values, marker='o')\n",
    "ax2.plot(keys, S2_rev_values, color = 'red')\n",
    "ax.set_xlabel('max width of streets kept (m)')\n",
    "ax.set_ylabel('fractional size of giant component')\n",
    "ax2.set_ylabel('second largest component')\n",
    "plt.title('Percolation test')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84931f-cff6-4cc4-bd68-c0693cde14e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8df60b1a-f2e5-499f-9961-aa05d3656906",
   "metadata": {},
   "source": [
    "# Network with OSMnx package (incomplete)\n",
    "\n",
    "to be completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085678ce-0078-42d1-ba26-41e005305993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afb832-eec0-4034-ae81-09ca8f18fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ox.graph_from_place(\"Rome, Italy\", network_type = 'drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a9527-1890-4fc9-8b50-fd6ef924c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = ox.graph_from_place(\"Milan, Lombardy, Italy\", network_type = 'drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96793af0-a64e-4313-8c18-dd6c9e5f3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(M)\n",
    "gdf_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16683fa-1314-4783-9560-234408e541f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what sized area does our network cover in square meters?\n",
    "M_proj = ox.project_graph(M)\n",
    "nodes_proj = ox.graph_to_gdfs(M_proj, edges=False)\n",
    "graph_area_m = nodes_proj.unary_union.convex_hull.area\n",
    "graph_area_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a83571b-d645-4bf6-9b44-d84ddd57150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some basic stats about the network\n",
    "ox.basic_stats(M_proj, area=graph_area_m, clean_int_tol=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93439706-3fd9-45e3-8caa-d73f8f34c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert graph to line graph so edges become nodes and vice versa\n",
    "edge_centrality = nx.closeness_centrality(nx.line_graph(M))\n",
    "nx.set_edge_attributes(M, edge_centrality, \"edge_centrality\")\n",
    "\n",
    "# color edges in original graph with closeness centralities from line graph\n",
    "ec = ox.plot.get_edge_colors_by_attr(M, \"edge_centrality\", cmap=\"inferno\")\n",
    "fig, ax = ox.plot_graph(M, edge_color=ec, edge_linewidth=2, node_size=0)\n",
    "\n",
    "#NB takes about 13 minutes to execute for milan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e621e5d0-821e-4337-8365-53d461452004",
   "metadata": {},
   "source": [
    "Just like at the beginning, our problem with having an osmnx network is that there is no width attribute on these roads. How can we do what we need to without width? we can't calculate it because the road network is not made up of polygons, but of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fab45c-f480-455f-8dd6-adc0d69288e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize = (8,8))\n",
    "gdf_nodes.plot(markersize = 0.1, ax = ax, color = 'red')\n",
    "gdf_edges.plot(linewidth = 0.5, ax = ax, alpha = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b927ba-8372-4f4b-913c-06dce22be09c",
   "metadata": {},
   "source": [
    "Let's test the method of calculating width with a Voronoi tessellation.\n",
    "first let's take two adjacent nodes, calculate their distance and then create a voronoi tessellation between them by using geoplot.voronoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c1f3f-dcd2-4975-bd0c-9faca3a8b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a node and its neighbors\n",
    "\n",
    "M.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83f1dc-7f6a-4662-98b7-f4e824ab21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10371529\n",
    "adj = M.adj[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf1e10-8e6b-485a-9b62-7bbb8974d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_nodes, adj_edges = ox.graph_to_gdfs(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbaa94b-8a85-413f-a318-7692b5e5623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83be5a-ef54-4a6a-a56e-2ef8519eca62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
